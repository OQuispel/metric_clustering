{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tempfile\n",
    "from shutil import copy\n",
    "import pandas as pd\n",
    "from multiprocessing import Pool\n",
    "import subprocess\n",
    "import scipy.spatial.distance as ssd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.2788001\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "import matplotlib.pyplot as plt\n",
    "from function import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approach\n",
    "1. Generate list of maps to compare\n",
    "1. Generate list of all required comparisons\n",
    "1. Pre-load all csv maps into Python\n",
    "1. Select map pair to compare\n",
    "1. Create temp folder\n",
    "1. Provide temp folder with maskland and mask file\n",
    "1. Generate asc version of csv maps that are to be compared\n",
    "1. Generate CSL and log file for the comparison and copy to temp folder\n",
    "1. Copy legends folder to temp folder\n",
    "1. Run comparison in MCK\n",
    "1. Extract required stats from outputfile\n",
    "1. Delete temp folder with all files\n",
    "1. Go back and repeat from step 4 until all comparisons have been run\n",
    "1. Export all data to disk\n",
    "<img src=\"PythonPipeline.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Help Functions\n",
    "<b><font size=\"4\">Any function not defined here can be found in function.py</font></b><br>\n",
    "This distinction was necessary as pool would not run with the function defined in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_df(maps, stats, metric):\n",
    "    \"\"\"This function takes the output from the run comparisons function for single map comparison metrics and returns the distance matrix\"\"\"\n",
    "    #create base df to form basis for distance matrix\n",
    "    df = pd.DataFrame(index=maps)\n",
    "    df[metric] = stats\n",
    "    #calculate euclidean distance between all values then change to matrix form\n",
    "    matrix = ssd.squareform(ssd.pdist(df))\n",
    "    df_clean = pd.DataFrame(matrix, index=single_maps, columns=single_maps)\n",
    "    \n",
    "    #save df to disk\n",
    "    csv_name = csv_dir + metric + '_df.csv'\n",
    "    df_clean.to_csv(csv_name, index=False)\n",
    "    return df_clean\n",
    "\n",
    "def multi_df(map1, map2, stats, metric):\n",
    "    \"\"\"This function takes the output from the run comparisons function for multi map comparison metrics and returns the distance matrix\"\"\"\n",
    "    #Create two dataframes with swapped map columns\n",
    "    df = pd.DataFrame()\n",
    "    df['map1'] = [x for x in map1]\n",
    "    df['map2'] = [x for x in map2]\n",
    "    df[metric] = stats\n",
    "    df2 = df\n",
    "    df2 = df2[[ 'map2', 'map1', metric]]\n",
    "    df2.columns = ['map1', 'map2', metric]      \n",
    "    df_concat = pd.concat([df, df2])\n",
    "    df_pivot = df_concat.pivot(index='map2', columns='map1', values=metric)\n",
    "    \n",
    "    #clean up the presentation\n",
    "    #Remove unecessary labeling\n",
    "    index = df_pivot.index.union(df_pivot.columns)\n",
    "    df_clean = df_pivot.reindex(index=index, columns=index)\n",
    "    #reindex to correct numerical order\n",
    "    ordered = df_clean.index.to_series().str.rsplit('p').str[-1].astype(int).sort_values()\n",
    "    df_clean = df_clean.reindex(index=ordered.index, columns=ordered.index).fillna(1).round(decimals=3)\n",
    "    \n",
    "    #save df to disk\n",
    "    csv_name = csv_dir + metric + '_df.csv'\n",
    "    df_clean.to_csv(csv_name, index=False)\n",
    "    return df_clean\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Variables Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#directory where the dataframes containing output are stored\n",
    "csv_dir = 'C:/LUMOS/MCK/Output_DFs/'\n",
    "\n",
    "#generate metric lists for all comparisons - move them after creation in nb\n",
    "# kfuzzy_id = ['kfuzzy'] * len(map_pairs)\n",
    "# alloc_id = ['alloc'] * len(map_pairs)\n",
    "# quant_id = ['quant'] * len(map_pairs)\n",
    "# clump_id = ['clump'] * len(map_list)\n",
    "# nrpatch_id = ['nrpatch'] * len(map_list)\n",
    "# simpson_id = ['simpson'] * len(map_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metric_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This list contains the metrics available for analysis and the metric_id that needs to be assigned to the metric_id list to generate the desired output, and the value passed to the extract stats function:<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Metric                        |   ID   | stats id |              note             |\n",
    "|-------------------------------|--------|----------|-------------------------------|\n",
    "|   Kappa                       | kappa  |     0    |                               |\n",
    "|   Overall Accuracy            | kappa  |     0    | this is calculated with kappa |\n",
    "|   Fuzzy Kappa                 | kfuzzy |     1    |                      |\n",
    "|   Allocation Disagreement     | alloc  |     2    |                      | \n",
    "|   Quantity Disagreement       | quant  |     3    |                      | \n",
    "|   Fractal Dimension           | fractal|     4    |                      |\n",
    "|   Clumpiness                  | clump  |     5    |                      |\n",
    "|   Number of Patches           | nrpatch|     6    |                      |\n",
    "|   Simpson's Diversity Index   | simpson|     7    |                      |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Kappa and Overall Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a zipped list to pass to the comparison function containing information about the maps and the metric to use\n",
    "kappa_id = ['kappa'] * len(map_pairs)\n",
    "pair_id = list(np.arange(0,len(map_pairs),1))\n",
    "pairs = zip(pair_id, kappa_id)\n",
    "num_processors = 4\n",
    "p=Pool(processes=num_processors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run with ascs reloading (edit out numpy2asc loop bottom of function.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store output as list\n",
    "acc = []\n",
    "kappa = []\n",
    "runtime = []\n",
    "kappa_maps1 = []\n",
    "kappa_maps2 = []\n",
    "\n",
    "start = timeit.default_timer()\n",
    "\n",
    "for n1, n2, ac, kap in p.starmap(run_comparisons, pairs):\n",
    "    kappa_maps1.append(n1)\n",
    "    kappa_maps2.append(n2)\n",
    "    acc.append(ac)\n",
    "    kappa.append(kap)  \n",
    "stop = timeit.default_timer()\n",
    "\n",
    "print(stop - start)\n",
    "# Create df for kappa and save it to disk\n",
    "df_kappa = multi_df(kappa_maps1, kappa_maps2, kappa, 'kappa')\n",
    "df_kappa.head(5)\n",
    "# Create df for overal accuracy and save it to disk\n",
    "df_acc = multi_df(kappa_maps1, kappa_maps2, acc, 'accuracy')\n",
    "df_acc.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run with ascs preloaded (edit out map_pairs in function.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store output as list\n",
    "acc = []\n",
    "kappa = []\n",
    "runtime = []\n",
    "kappa_maps1 = []\n",
    "kappa_maps2 = []\n",
    "\n",
    "start = timeit.default_timer()\n",
    "\n",
    "for n1, n2, ac, kap in p.starmap(run_comparisons2, pairs):\n",
    "    kappa_maps1.append(n1)\n",
    "    kappa_maps2.append(n2)\n",
    "    acc.append(ac)\n",
    "    kappa.append(kap)  \n",
    "stop = timeit.default_timer()\n",
    "\n",
    "print(stop - start)\n",
    "# Create df for kappa and save it to disk\n",
    "df_kappa = multi_df(kappa_maps1, kappa_maps2, kappa, 'kappa')\n",
    "df_kappa.head(5)\n",
    "# Create df for overal accuracy and save it to disk\n",
    "df_acc = multi_df(kappa_maps1, kappa_maps2, acc, 'accuracy')\n",
    "df_acc.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#p.starmap(run_comparisons, pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Fractal Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a zipped list to pass to the comparison function containing information about the maps and the metric to use\n",
    "fractal_id = ['fractal'] * len(map_list)\n",
    "pair_id = list(np.arange(0,len(map_list),1))\n",
    "pairs = zip(pair_id, fractal_id)\n",
    "num_processors = 4\n",
    "p=Pool(processes=num_processors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.76012849999999\n"
     ]
    }
   ],
   "source": [
    "#store output as list\n",
    "frac = []\n",
    "frac_maps = []\n",
    "\n",
    "start = timeit.default_timer()\n",
    "\n",
    "for n1, n2, fr1, fr2 in p.starmap(run_comparisons, pairs):\n",
    "    frac_maps.append(n1)\n",
    "    frac_maps.append(n2)\n",
    "    frac.append(fr1)\n",
    "    if fr2 != 999:\n",
    "        frac.append(fr2)\n",
    "stop = timeit.default_timer()\n",
    "\n",
    "print(stop - start)\n",
    "\n",
    "# Create df for fractal dimension and save it to disk\n",
    "df_frac = single_df(frac_maps, frac, 'fractal')\n",
    "df_frac"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
