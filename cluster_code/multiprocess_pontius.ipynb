{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "import tqdm\n",
    "from function_pontius import *\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-21T10:57:41.974506Z",
     "iopub.status.busy": "2020-10-21T10:57:41.974506Z",
     "iopub.status.idle": "2020-10-21T10:57:41.988510Z",
     "shell.execute_reply": "2020-10-21T10:57:41.987509Z",
     "shell.execute_reply.started": "2020-10-21T10:57:41.974506Z"
    }
   },
   "source": [
    "## Pontius metrics in this notebook:\n",
    "1. Overall Difference (OD)\n",
    "1. Overal Quantity Component (OQC)\n",
    "1. Overall Allocation Component (OAC)\n",
    "1. Overal Quantity Disagreement 'Nature' (OQD_n) --> Note that this is a categorical metric calculation\n",
    "\n",
    "Using the contingency table from the previous metrics this notebook also calculates:\n",
    "1. Overall Accuracy (OA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-30T09:59:30.218537Z",
     "iopub.status.busy": "2020-10-30T09:59:30.217536Z",
     "iopub.status.idle": "2020-10-30T10:04:49.238439Z",
     "shell.execute_reply": "2020-10-30T10:04:49.238439Z",
     "shell.execute_reply.started": "2020-10-30T09:59:30.218537Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 190/190 [05:18<00:00,  1.68s/it]\n"
     ]
    }
   ],
   "source": [
    "# Assign focal land use class used for OQD_n; defaults to 'Nature' (class_id=22)\n",
    "class_id = 22\n",
    "\n",
    "# Lists to store the map and metric return values\n",
    "maps1 = []\n",
    "maps2 = []\n",
    "oa = []\n",
    "od = []\n",
    "oqd = []\n",
    "oad = []\n",
    "oqd_n = []\n",
    "\n",
    "#number of workers to use\n",
    "num_workers = 12\n",
    "\n",
    "with Pool(num_workers) as p:\n",
    "    iterable =  [(i, class_id) for i in range(multi_its)]\n",
    "    for n1, n2, acc, diff, qd, ad, qd_n in tqdm.tqdm(p.istarmap(calc_multi, iterable),\n",
    "                       total=len(iterable)):\n",
    "        maps1.append(n1)\n",
    "        maps2.append(n2)\n",
    "        oa.append(acc)\n",
    "        od.append(diff)\n",
    "        oqd.append(qd)\n",
    "        oad.append(ad)\n",
    "        oqd_n.append(qd_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-30T10:11:41.362462Z",
     "iopub.status.busy": "2020-10-30T10:11:41.361462Z",
     "iopub.status.idle": "2020-10-30T10:11:41.417475Z",
     "shell.execute_reply": "2020-10-30T10:11:41.417475Z",
     "shell.execute_reply.started": "2020-10-30T10:11:41.362462Z"
    }
   },
   "outputs": [],
   "source": [
    "multi_df(maps1, maps2, oa, 'overallaccuracy')\n",
    "multi_df(maps1, maps2, od, 'overalldifference')\n",
    "multi_df(maps1, maps2, oqd, 'overallquantitydifference')\n",
    "multi_df(maps1, maps2, oad, 'overallallocationdifference')\n",
    "#Change used name based on the landuse class analyzed\n",
    "df_id = 'quantitydifferencecategorical_' + str(class_id)\n",
    "multi_df(maps1, maps2, oqd_n, df_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old code for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import function_pontius_old as fpont\n",
    "#from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign focal land use class used for OQD_n; defaults to 'Nature' (class_id=22)\n",
    "class_id = 22\n",
    "\n",
    "# Lists to store the map and metric return values\n",
    "maps11 = []\n",
    "maps22 = []\n",
    "oa1 = []\n",
    "od1 = []\n",
    "oqd1 = []\n",
    "oad1 = []\n",
    "oqd_n1 = []\n",
    "\n",
    "#number of workers to use\n",
    "num_workers = 12\n",
    "\n",
    "with Pool(num_workers) as p:\n",
    "    iterable =  [(i, class_id) for i in range(multi_its)]\n",
    "    for n1, n2, acc, diff, qd, ad, qd_n in tqdm.tqdm(p.istarmap(fpont.calc_multi, iterable),\n",
    "                       total=len(iterable)):\n",
    "        maps11.append(n1)\n",
    "        maps22.append(n2)\n",
    "        oa1.append(acc)\n",
    "        od1.append(diff)\n",
    "        oqd1.append(qd)\n",
    "        oad1.append(ad)\n",
    "        oqd_n1.append(qd_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare old vs new code output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oa = pd.read_csv('C:/LUMOS/MCK/output_DFs/compare/overallaccuracy_df.csv')\n",
    "oad = pd.read_csv('C:/LUMOS/MCK/output_DFs/compare/overallallocationdifference_df.csv')\n",
    "od = pd.read_csv('C:/LUMOS/MCK/output_DFs/compare/overalldifference_df.csv')\n",
    "oqd = pd.read_csv('C:/LUMOS/MCK/output_DFs/compare/overallquantitydifference_df.csv')\n",
    "oqd_n2 = pd.read_csv('C:/LUMOS/MCK/output_DFs/compare/quantitydifferencecategorical_22_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-30T10:10:17.574807Z",
     "iopub.status.busy": "2020-10-30T10:10:17.574807Z",
     "iopub.status.idle": "2020-10-30T10:10:17.598813Z",
     "shell.execute_reply": "2020-10-30T10:10:17.598813Z",
     "shell.execute_reply.started": "2020-10-30T10:10:17.574807Z"
    }
   },
   "outputs": [],
   "source": [
    "oa2 = pd.read_csv('C:/LUMOS/MCK/output_DFs/compare/overallaccuracy_df.csv')\n",
    "oad2 = pd.read_csv('C:/LUMOS/MCK/output_DFs/compare/overallallocationdifference_df.csv')\n",
    "od2 = pd.read_csv('C:/LUMOS/MCK/output_DFs/compare/overalldifference_df.csv')\n",
    "oqd2 = pd.read_csv('C:/LUMOS/MCK/output_DFs/compare/overallquantitydifference_df.csv')\n",
    "oqd_n2 = pd.read_csv('C:/LUMOS/MCK/output_DFs/compare/quantitydifferencecategorical_22_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-30T10:10:48.339302Z",
     "iopub.status.busy": "2020-10-30T10:10:48.339302Z",
     "iopub.status.idle": "2020-10-30T10:10:48.343303Z",
     "shell.execute_reply": "2020-10-30T10:10:48.343303Z",
     "shell.execute_reply.started": "2020-10-30T10:10:48.339302Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(oa2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-30T10:10:31.483787Z",
     "iopub.status.busy": "2020-10-30T10:10:31.483787Z",
     "iopub.status.idle": "2020-10-30T10:10:31.496910Z",
     "shell.execute_reply": "2020-10-30T10:10:31.496910Z",
     "shell.execute_reply.started": "2020-10-30T10:10:31.483787Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unable to coerce to Series, length must be 20: given 190",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-de35dd09578d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0moa\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0moa2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\ops.py\u001b[0m in \u001b[0;36mf\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m   2089\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2090\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2091\u001b[1;33m         \u001b[0mother\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_align_method_FRAME\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2092\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2093\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABCDataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\ops.py\u001b[0m in \u001b[0;36m_align_method_FRAME\u001b[1;34m(left, right, axis)\u001b[0m\n\u001b[0;32m   1983\u001b[0m           not isinstance(right, (ABCSeries, ABCDataFrame))):\n\u001b[0;32m   1984\u001b[0m         \u001b[1;31m# GH17901\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1985\u001b[1;33m         \u001b[0mright\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_series\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1986\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1987\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mright\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\ops.py\u001b[0m in \u001b[0;36mto_series\u001b[1;34m(right)\u001b[0m\n\u001b[0;32m   1945\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1946\u001b[0m                 raise ValueError(msg.format(req_len=len(left.columns),\n\u001b[1;32m-> 1947\u001b[1;33m                                             given_len=len(right)))\n\u001b[0m\u001b[0;32m   1948\u001b[0m             \u001b[0mright\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mleft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor_sliced\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1949\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mright\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unable to coerce to Series, length must be 20: given 190"
     ]
    }
   ],
   "source": [
    "oa == oa2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_multi(pair_id, class1=22):\n",
    "    \"\"\"This function is the basis for calculating Pontius' metrics (2014), starting off by computing the confusion matrix for two provided maps and \n",
    "    ending with the Total Disagreement if it is assigned to be calculated.\"\"\"\n",
    "    map1 = pontius_pairs[pair_id][0]\n",
    "    map2 = pontius_pairs[pair_id][1]\n",
    "    m1_dir = abs_dir + 'ascmaps/' + map1 + '.asc'\n",
    "    m2_dir = abs_dir + 'ascmaps/' + map2 + '.asc'\n",
    "    m1 = np.loadtxt(m1_dir, skiprows=6)\n",
    "    m2 = np.loadtxt(m2_dir, skiprows=6)\n",
    "    #compute confusion matrix\n",
    "    cm = conf_mat(m1, m2)\n",
    "    # turn array into df so that ppy can work with it\n",
    "    rows_cols = ['class' + str(i) for i in range(28)]\n",
    "    rows_cols.remove('class23')\n",
    "    rows_cols.remove('class27')\n",
    "    df = pd.DataFrame(data=cm, index=rows_cols, columns=rows_cols)\n",
    "    #create object to run ppy code\n",
    "    df_pont = pont.pontiPy(df)\n",
    "    return df_pont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfpont = calc_multi(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfpont.matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfpy = calc_multi(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfpy.matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map1 = np.loadtxt('C:/LUMOS/MCK/ascmaps/map0.asc', skiprows=6)\n",
    "map2 = np.loadtxt('C:/LUMOS/MCK/ascmaps/map1.asc', skiprows=6)\n",
    "map1 = map1.astype('int32')\n",
    "map2 = map1.astype('int32')\n",
    "x1 = np.concatenate(map1, axis=0)\n",
    "x2 = np.concatenate(map2, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "array=dfpy\n",
    "\n",
    "df_cm = pd.DataFrame(array)\n",
    "plt.figure(figsize=(14,14))\n",
    "sn.set(font_scale=1.4) # for label size\n",
    "sn.heatmap(df_cm, linewidths=1) # font size\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,14))\n",
    "sn.set(font_scale=1.4) # for label size\n",
    "sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 16}) # font size\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_cols = ['cat' + str(i + 1) for i in range(28)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(data=cm1, index=rows_cols, columns=rows_cols)\n",
    "df2 = pd.DataFrame(data=cm2, index=rows_cols, columns=rows_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "# import some data to play with\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "class_names = iris.target_names\n",
    "\n",
    "# Split the data into a training set and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# Run classifier, using a model that is too regularized (C too low) to see\n",
    "# the impact on the results\n",
    "classifier = svm.SVC(kernel='linear', C=0.01).fit(X_train, y_train)\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "titles_options = [(\"Confusion matrix, without normalization\", None),\n",
    "                  (\"Normalized confusion matrix\", 'true')]\n",
    "for title, normalize in titles_options:\n",
    "    disp = plot_confusion_matrix(classifier, X_test, y_test,\n",
    "                                 display_labels=class_names,\n",
    "                                 cmap=plt.cm.Blues,\n",
    "                                 normalize=normalize)\n",
    "    disp.ax_.set_title(title)\n",
    "\n",
    "    print(title)\n",
    "    print(disp.confusion_matrix)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
